# ------------------LangSmith tracing------------------
LANGCHAIN_PROJECT="default"
LANGCHAIN_API_KEY="lsv2_pt_..."
LANGCHAIN_TRACING_V2="true"
# Set to true when ready to run evals, _and_ have the results uploaded to LangSmith.
# If false, evals will still run, but results will not be saved in LangSmith.
LANGCHAIN_TEST_TRACKING="false"


# ------------------LLM Provider Keys------------------
# Defaults to Anthropic models.
ANTHROPIC_API_KEY=""
OPENAI_API_KEY=""
GOOGLE_API_KEY=""


# ------------------Infrastructure---------------------
# Daytona API key for creating & accessing the cloud sandbox.
DAYTONA_API_KEY=""


# ------------------------Tools------------------------
# Firecrawl API key for calling the get URL contents tool.
FIRECRAWL_API_KEY=""


# ------------------Github App Secrets-----------------
GITHUB_APP_NAME="open-swe-dev" # this must match the name of your GitHub app, excluding spaces
GITHUB_APP_ID=""
# App secret key. Should be multi-line.
GITHUB_APP_PRIVATE_KEY="-----BEGIN RSA PRIVATE KEY-----
...add your private key here...
-----END RSA PRIVATE KEY-----
"
# Secret key for verifying GitHub webhook events.
GITHUB_WEBHOOK_SECRET=""
# GitHub username to tag for triggering runs from PR comments (without the @ symbol)
GITHUB_TRIGGER_USERNAME="open-swe"


# ------------------------Other------------------------
# Defaults to 2024 if not set.
# LGP will automatically set this for you in production.
PORT="2024"
# Used to create a run URL when replying to a GitHub issue comment.
# Should be the URL of the web app. Localhost in dev, production URL
# in production.
OPEN_SWE_APP_URL="http://localhost:3000"
# Encryption key for secrets (32-byte hex string for AES-256)
# Should be the same value as the one used in the web app, so that secrets
# encrypted in the web app can be decrypted in the agent.
SECRETS_ENCRYPTION_KEY=""
# Whether or not to append the string "[skip ci]" to the commit message.
# See the documentation for how to set this up: docs.langchain.com/labs/swe/setup/ci#skip-ci-until-last-commit
SKIP_CI_UNTIL_LAST_COMMIT="true"

# For the CLI to work, you need to set these variables.
# OPEN_SWE_LOCAL_MODE=false
# OPEN_SWE_LOCAL_PROJECT_PATH=""

# List of GitHub usernames that are allowed to use Open SWE without providing API keys
# This is only used in production. In development every user is an "allowed user".
# Must be a valid JSON array of strings.
NEXT_PUBLIC_ALLOWED_USERS_LIST='["your-github-username", "teammate-username"]'

# ------------------Fallback Model Configuration------------------
# Configure fallback models for each provider and task.
# If not set, will use the default models defined in code.
# Format: FALLBACK_{PROVIDER}_{TASK}_MODEL
# 
# Provider options: ANTHROPIC, OPENAI, GOOGLE_GENAI
# Task options: PLANNER, PROGRAMMER, REVIEWER, ROUTER, SUMMARIZER
#
# Example for Anthropic:
# FALLBACK_ANTHROPIC_PLANNER_MODEL="claude-opus-4-5"
# FALLBACK_ANTHROPIC_PROGRAMMER_MODEL="claude-opus-4-5"
# FALLBACK_ANTHROPIC_REVIEWER_MODEL="claude-opus-4-5"
# FALLBACK_ANTHROPIC_ROUTER_MODEL="claude-haiku-4-5-latest"
# FALLBACK_ANTHROPIC_SUMMARIZER_MODEL="claude-opus-4-5"
#
# Example for OpenAI:
# FALLBACK_OPENAI_PLANNER_MODEL="gpt-5-codex"
# FALLBACK_OPENAI_PROGRAMMER_MODEL="gpt-5-codex"
# FALLBACK_OPENAI_REVIEWER_MODEL="gpt-5-codex"
# FALLBACK_OPENAI_ROUTER_MODEL="gpt-5-nano"
# FALLBACK_OPENAI_SUMMARIZER_MODEL="gpt-5-mini"
#
# Example for Google GenAI:
# FALLBACK_GOOGLE_GENAI_PLANNER_MODEL="gemini-2.5-pro"
# FALLBACK_GOOGLE_GENAI_PROGRAMMER_MODEL="gemini-2.5-pro"
# FALLBACK_GOOGLE_GENAI_REVIEWER_MODEL="gemini-2.5-flash"
# FALLBACK_GOOGLE_GENAI_ROUTER_MODEL="gemini-2.5-flash"
# FALLBACK_GOOGLE_GENAI_SUMMARIZER_MODEL="gemini-2.5-pro"
#
# Uncomment and modify the models you want to override:
# FALLBACK_ANTHROPIC_PLANNER_MODEL=""
# FALLBACK_ANTHROPIC_PROGRAMMER_MODEL=""
# FALLBACK_ANTHROPIC_REVIEWER_MODEL=""
# FALLBACK_ANTHROPIC_ROUTER_MODEL=""
# FALLBACK_ANTHROPIC_SUMMARIZER_MODEL=""
# FALLBACK_OPENAI_PLANNER_MODEL=""
# FALLBACK_OPENAI_PROGRAMMER_MODEL=""
# FALLBACK_OPENAI_REVIEWER_MODEL=""
# FALLBACK_OPENAI_ROUTER_MODEL=""
# FALLBACK_OPENAI_SUMMARIZER_MODEL=""
# FALLBACK_GOOGLE_GENAI_PLANNER_MODEL=""
# FALLBACK_GOOGLE_GENAI_PROGRAMMER_MODEL=""
# FALLBACK_GOOGLE_GENAI_REVIEWER_MODEL=""
# FALLBACK_GOOGLE_GENAI_ROUTER_MODEL=""
# FALLBACK_GOOGLE_GENAI_SUMMARIZER_MODEL=""

# ------------------Default Model Configuration------------------
# Configure default models for each task (when user hasn't selected a model).
# If not set, will use the default models defined in code.
# Format: DEFAULT_{TASK}_MODEL
# 
# Task options: PLANNER, PROGRAMMER, REVIEWER, ROUTER, SUMMARIZER
# Model format: {provider}:{model-name}
#   - Provider options: anthropic, openai, google-genai
#   - Examples:
#     - anthropic:claude-opus-4-5
#     - openai:gpt-5-codex
#     - google-genai:gemini-2.5-pro
#
# Default values (if not set):
# DEFAULT_PLANNER_MODEL="anthropic:claude-opus-4-5"
# DEFAULT_PROGRAMMER_MODEL="anthropic:claude-opus-4-5"
# DEFAULT_REVIEWER_MODEL="anthropic:claude-opus-4-5"
# DEFAULT_ROUTER_MODEL="anthropic:claude-haiku-4-5"
# DEFAULT_SUMMARIZER_MODEL="anthropic:claude-haiku-4-5"
#
# Uncomment and modify the default models you want to override:
# DEFAULT_PLANNER_MODEL="anthropic:claude-opus-4-5"
# DEFAULT_PROGRAMMER_MODEL="anthropic:claude-opus-4-5"
# DEFAULT_REVIEWER_MODEL="anthropic:claude-opus-4-5"
# DEFAULT_ROUTER_MODEL="anthropic:claude-haiku-4-5"
# DEFAULT_SUMMARIZER_MODEL="anthropic:claude-haiku-4-5"
#
# Example: Use Gemini models as default
# DEFAULT_PLANNER_MODEL="google-genai:gemini-2.5-pro"
# DEFAULT_PROGRAMMER_MODEL="google-genai:gemini-2.5-pro"
# DEFAULT_REVIEWER_MODEL="google-genai:gemini-2.5-flash"
# DEFAULT_ROUTER_MODEL="google-genai:gemini-2.5-flash"
# DEFAULT_SUMMARIZER_MODEL="google-genai:gemini-2.5-pro"

# Example: Use OpenAI models as default
# DEFAULT_PLANNER_MODEL="openai:gpt-5-codex"
# DEFAULT_PROGRAMMER_MODEL="openai:gpt-5-codex"
# DEFAULT_REVIEWER_MODEL="openai:gpt-5-codex"
# DEFAULT_ROUTER_MODEL="openai:gpt-5-nano"
# DEFAULT_SUMMARIZER_MODEL="openai:gpt-5-mini"
